{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines: 10837\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "DATADIRECTORY=\"./simData\"\n",
    "IMAGEDIRECTORY=\"./simData/IMG\"\n",
    "DRIVINGLOG=DATADIRECTORY+\"/driving_log.csv\"\n",
    "lines=[]\n",
    "with open(DRIVINGLOG) as csvFile:\n",
    "    reader=csv.reader(csvFile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "print(\"lines:\", len(lines))\n",
    "\n",
    "import cv2\n",
    "\n",
    "CENTERIMAGE=0\n",
    "STEERINGMEASUEMENT=3\n",
    "CAMERAS=3\n",
    "# CENTER, LEFT, RIGHT\n",
    "STERRINGADJUSTMENT=[0, .25, -.25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def readImage(imagePathOnRemote):\n",
    "    filename=imagePathOnRemote.split(\"/\")[-1]\n",
    "    imagePath=IMAGEDIRECTORY+\"/\"+filename\n",
    "    image=cv2.imread(imagePath)\n",
    "    #print(\"imagePath:\", imagePath, \"image.shape:\", image.shape)\n",
    "    return image;\n",
    "\n",
    "def generator(lines, batchSize=128):\n",
    "    #print(\"lines:\", len(lines))\n",
    "    numberOfSamples = len(lines)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        lines=sklearn.utils.shuffle(lines) # every epoch\n",
    "        #print(\"shuffled lines:\", len(lines))\n",
    "        for offset in range(0, numberOfSamples, batchSize):\n",
    "            batchOfLines = lines[offset:offset+batchSize]\n",
    "\n",
    "            images=[]\n",
    "            steeringMeasurements=[]\n",
    "\n",
    "            for line in batchOfLines:\n",
    "                for camera in range(CAMERAS):\n",
    "                    imagePathOnRemote=line[camera]\n",
    "                    image=readImage(imagePathOnRemote)\n",
    "                    if (image is None):\n",
    "                        print (\"line:\", line)\n",
    "                        print(\"image:\", image, \", imagePath:\", imagePath)\n",
    "                        exit\n",
    "                    images.append(image)\n",
    "                    steering=float(line[STEERINGMEASUEMENT])+STERRINGADJUSTMENT[camera]\n",
    "                    steeringMeasurements.append(steering)\n",
    "                    images.append(cv2.flip(image,1))\n",
    "                    steeringMeasurements.append(steering*-1)\n",
    "                    assert len(images)==len(steeringMeasurements)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(steeringMeasurements)\n",
    "            assert len(X_train)==len(y_train)\n",
    "            #print(\"X_train.shape:\", X_train.shape, \"y_train.shape:\", y_train.shape)\n",
    "            #print(\"X_train[0].shape:\", X_train[0].shape)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_samples: 8669 validation_samples: 2168\n",
      "train_samples[0]: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "print(\"train_samples:\", len(train_samples), \"validation_samples:\", len(validation_samples))\n",
    "print(\"train_samples[0]:\",len(train_samples[0]))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batchSize=128)\n",
    "validation_generator = generator(validation_samples, batchSize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleImage.shape: (160, 320, 3)\n",
      "XtrainInputShape: (160, 320, 3)\n",
      "Epoch 1/20\n",
      "8448/8669 [============================>.] - ETA: 0s - loss: 1.1823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9216/8669 [===============================] - 28s - loss: 1.1524 - val_loss: 0.0680\n",
      "Epoch 2/20\n",
      "9216/8669 [===============================] - 23s - loss: 0.7123 - val_loss: 0.0651\n",
      "Epoch 3/20\n",
      "9216/8669 [===============================] - 22s - loss: 0.4593 - val_loss: 0.0658\n",
      "Epoch 4/20\n",
      "9216/8669 [===============================] - 22s - loss: 0.3268 - val_loss: 0.0644\n",
      "Epoch 5/20\n",
      "9216/8669 [===============================] - 22s - loss: 0.2437 - val_loss: 0.0613\n",
      "Epoch 6/20\n",
      "9006/8669 [===============================] - 25s - loss: 0.1902 - val_loss: 0.0667\n",
      "Epoch 7/20\n",
      "9216/8669 [===============================] - 23s - loss: 0.1446 - val_loss: 0.0591\n",
      "Epoch 8/20\n",
      "9216/8669 [===============================] - 23s - loss: 0.1227 - val_loss: 0.0612\n",
      "Epoch 9/20\n",
      "9216/8669 [===============================] - 24s - loss: 0.1175 - val_loss: 0.0663\n",
      "Epoch 10/20\n",
      "4608/8669 [==============>...............] - ETA: 8s - loss: 0.1017 "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras as keras\n",
    "\n",
    "sampleImage=readImage(lines[0][0])\n",
    "print(\"sampleImage.shape:\", sampleImage.shape)\n",
    "XtrainInputShape=sampleImage.shape[0:len(sampleImage.shape)]\n",
    "print (\"XtrainInputShape:\", XtrainInputShape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 127.5) - 1, input_shape=XtrainInputShape, output_shape=XtrainInputShape))\n",
    "#model.add(Lambda(lambda x: (x / 127.5) - 1, input_shape=(3,80,320), output_shape=(3,80,320)))\n",
    "\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "\n",
    "# nvidia model\n",
    "# keras.layers.normalization.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "\n",
    "##\n",
    "model.add(Dense(1))\n",
    "\n",
    "adamOptimizer=keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='mse', optimizer=adamOptimizer)\n",
    "#model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "history_object=model.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator,\n",
    "                                   nb_val_samples=len(validation_samples), nb_epoch=20)\n",
    "\n",
    "#adamOptimizer=keras.optimizers.Adam(lr=0.0001)\n",
    "#model.compile(optimizer=adamOptimizer, loss='mse', metrics=['accuracy'])\n",
    "#history_object=model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=20)\n",
    "\n",
    "import datetime\n",
    "\n",
    "modelFilename=datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M\")+\".model\"\n",
    "print (\"saving model as:\", modelFilename)\n",
    "model.save(modelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "for key in history_object.history.keys():\n",
    "    print (\"key:\", key,\", values:\", history_object.history[key])\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
